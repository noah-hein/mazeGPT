![MazeGPT](media/logo_small.png)

[![Python 3.11](https://img.shields.io/badge/python-3.11-blue.svg)](https://www.python.org/downloads/release/python-3110/)
[![GitHub release](https://img.shields.io/github/release/noah-hein/mazeGPT)](https://GitHub.com/noah-hein/mazeGPT/releases/)
![Repo Size](https://img.shields.io/github/repo-size/noah-hein/mazeGPT)
[![linting: pylint](https://img.shields.io/badge/linting-pylint-yellowgreen)](https://github.com/pylint-dev/pylint)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://github.com/noah-hein/mazeGPT/blob/main/LICENSE)
[![GitHub last commit](https://img.shields.io/github/last-commit/noah-hein/mazeGPT.svg)](https://github.com/noah-hein/mazeGPT/commits/master)
[![GitHub pull-requests](https://img.shields.io/github/issues-pr/noah-hein/mazeGPT)](https://GitHub.com/noah-hein/mazeGPT/pull/)


[![GitHub stars](https://img.shields.io/github/stars/noah-hein/mazeGPT?style=social)](https://github.com/noah-hein/mazeGPT/stargazers)
[![GitHub watchers](https://img.shields.io/github/watchers/noah-hein/mazeGPT?style=social&label=Watch&maxAge=2592000)](https://GitHub.com/noah-hein/mazeGPT/watchers/)

#### Disclaimers
Does some maze generation and stuff. Working on this because I'm bored.
All this thing knows is mazes. By no means am I a master of machine learning. 
Hugging face and OpenAI are the ones to thank here.

|                                    |                                |
|:----------------------------------:|:------------------------------:|
| ![Inception](/media/inception.jpg) | ![Shining](/media/shining.jpg) |
|                                    |                                |


# üîç Table of Contents
* üåé [Introduction](#introduction)
* ‚è© [Quickstart](#-quickstart)
* üìó [Overview](docs/OVERVIEW.md#-overview)
  * ‚ö†Ô∏è [Problem](docs/OVERVIEW.md#-the-problem)
  * üìê [Representation](docs/OVERVIEW.md#-representing-a-maze)
  * üì§ [Tokenizer](docs/OVERVIEW.md#-tokenizer)
* üîß [Getting Started](docs/GETTING_STARTED.md)

## Introduction
["Attention Is All You Need"](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf) 
was a ground break paper in the world of machine learning in 2017.
The idea of a transformer has dramatically helped reduced the train time while improving the consistency
of attention across long periods of recurrent generation. The company [OpenAI](https://openai.com/) has two models ChatGPT and DALL¬∑E both implementing transformers to achieve 
incredible results. 

The objective of this research project was to implement a transformer model for generating mazes. 
While there are numerous existing maze algorithms that perform well, they tend to produce recurrent patterns despite 
being seeded randomly. The goal is to achieve mazes that are more random and chaotic in nature and mimic human behavior.

For more detailed information visit the [Overview](docs/OVERVIEW.md)

## üîß Quickstart
TODO

## Authors
- Noah Hein ([@noah-hein](https://github.com/noah-hein))





